if (class(train[, col]) != 'character') {
# Those in the tails of the distributions may be considered outliers
thres <- quantile(train[, col], probs = c(0.005, 0.995))
extremes <- cbind(extremes, as.data.frame(thres))
colnames(extremes)[ncol(extremes)] <- col
# Only those stricly outside interval (in case of high concentration)
outliers <- which(train[, col] < thres[1] |
train[, col] > thres[2])
killed <- unique(c(killed, outliers))
}
}
# Report the results
if (verbose == TRUE) {
cat('Total number of observations ("train"):', nrow(train), '\n')
cat('Number of outliers detected ("train"):', length(killed), '\n')
}
#Â Creating new variables
# Binary for outliers
train[, 'is_outlier'] <- 0
train[killed, 'is_outlier'] <- 1
# Binary for timedelta
train[, 'timedelta_bin'] <- as.numeric(train[, 'timedelta'] >= 400)
train[, 'timedelta_bin_int'] <- train[, 'timedelta'] *
train[, 'timedelta_bin']
# Categorical for kw_min_min
train[, 'kw_min_min_cat0'] <- 0
train[, 'kw_min_min_cat1'] <- 0
train[, 'kw_min_min_cat2'] <- 0
train[which(train[, 'kw_min_min'] ==  -1), 'kw_min_min_cat0'] <- 1
train[which(train[, 'kw_min_min'] ==   4), 'kw_min_min_cat1'] <- 1
train[which(train[, 'kw_min_min'] == 217), 'kw_min_min_cat2'] <- 1
# Binary kw_avg_max
train[, 'kw_avg_max_bin'] <- as.numeric(train[, 'kw_avg_max'] >= 1e5)
#Â Binary kw_min_avg
train[, 'kw_min_avg_bin'] <- as.numeric(train[, 'kw_min_avg'] >= 0)
#Â Binary LDA_0x
train[, 'LDA_01_bin'] <- as.numeric(train[, 'LDA_01'] < 0.1)
train[, 'LDA_02_bin'] <- as.numeric(train[, 'LDA_02'] < 0.1)
train[, 'LDA_03_bin'] <- as.numeric(train[, 'LDA_03'] < 0.1)
train[, 'LDA_04_bin'] <- as.numeric(train[, 'LDA_04'] < 0.1)
train[, 'LDA_01_bin_int'] <- train[, 'LDA_01'] * train[, 'LDA_01_bin']
train[, 'LDA_02_bin_int'] <- train[, 'LDA_02'] * train[, 'LDA_02_bin']
train[, 'LDA_03_bin_int'] <- train[, 'LDA_03'] * train[, 'LDA_03_bin']
train[, 'LDA_04_bin_int'] <- train[, 'LDA_04'] * train[, 'LDA_04_bin']
#Â Categorical title_subjectivity
q0 <- which(train[, 'title_subjectivity'] <  0.15)
q1 <- which(train[, 'title_subjectivity'] >= 0.15)
q2 <- which(train[, 'title_subjectivity'] >= 0.6)
train[, 'title_subjectivity_cat0'] <- 0
train[, 'title_subjectivity_cat1'] <- 0
train[, 'title_subjectivity_cat2'] <- 0
train[q0, 'title_subjectivity_cat0'] <- 1
train[q1, 'title_subjectivity_cat1'] <- 1
train[q2, 'title_subjectivity_cat2'] <- 1
# Categorical title_sentiment_polarity
q0 <- which(train[, 'title_sentiment_polarity'] <  0)
q1 <- which(train[, 'title_sentiment_polarity'] == 0)
q2 <- which(train[, 'title_sentiment_polarity'] >  0)
train[, 'title_sentiment_polarity_cat0'] <- 0
train[, 'title_sentiment_polarity_cat1'] <- 0
train[, 'title_sentiment_polarity_cat2'] <- 0
train[q0, 'title_sentiment_polarity_cat0'] <- 1
train[q1, 'title_sentiment_polarity_cat1'] <- 1
train[q2, 'title_sentiment_polarity_cat2'] <- 1
# Extract the date
urls <- strsplit(train[, 'url'], '/')
days <- sapply(urls, `[`, 6)
years <- sapply(urls, `[`, 4)
month <- sapply(urls, `[`, 5)
dates <- paste(years, month, days, sep = '-')
#Â Date
day.one <- as.Date('2013-01-01', '%Y-%m-%d')
train[, 'date'] <- as.Date(dates, '%Y-%m-%d')
train[, 'since_20130101'] <- as.numeric(train[, 'date'] - day.one)
# Year
train[, 'year'] <- years
train[, 'is_2013'] <- as.numeric(train[, 'year'] == '2013')
train[, 'is_2014'] <- as.numeric(train[, 'year'] == '2014')
# Month
train[, 'month'] <- month
train[, 'is_jan'] <- as.numeric(train[, 'month'] == '01')
train[, 'is_feb'] <- as.numeric(train[, 'month'] == '02')
train[, 'is_mar'] <- as.numeric(train[, 'month'] == '03')
train[, 'is_apr'] <- as.numeric(train[, 'month'] == '04')
train[, 'is_may'] <- as.numeric(train[, 'month'] == '05')
train[, 'is_jun'] <- as.numeric(train[, 'month'] == '06')
train[, 'is_jul'] <- as.numeric(train[, 'month'] == '07')
train[, 'is_aug'] <- as.numeric(train[, 'month'] == '08')
train[, 'is_sep'] <- as.numeric(train[, 'month'] == '09')
train[, 'is_oct'] <- as.numeric(train[, 'month'] == '10')
train[, 'is_nov'] <- as.numeric(train[, 'month'] == '11')
train[, 'is_dec'] <- as.numeric(train[, 'month'] == '12')
# Day
train[, 'day'] <- days
# Season
train[, 'season'] <- '4'  # Winter
train[which(paste(month, days) > '03 20'), 'season'] <- '1'  #Â Spring
train[which(paste(month, days) > '06 20'), 'season'] <- '2'  # Summer
train[which(paste(month, days) > '09 20'), 'season'] <- '3'  # Autumn
train[which(paste(month, days) > '12 20'), 'season'] <- '4'  #Â Winter
train[, 'is_spring'] <- as.numeric(train[, 'season'] == '1')
train[, 'is_summer'] <- as.numeric(train[, 'season'] == '2')
train[, 'is_autumn'] <- as.numeric(train[, 'season'] == '3')
train[, 'is_winter'] <- as.numeric(train[, 'season'] == '4')
# Daily scores
# (checked days from beginning to end have some news)
counts <- tapply(rep(1, nrow(train)), train[, 'date'], sum)
avg <- tapply(train[, 'popularity'], train[, 'date'], mean)
sds <- tapply(train[, 'popularity'], train[, 'date'], sd)
m1 <- match(as.character(train[, 'date']), names(counts))
m2 <- match(as.character(train[, 'date']), names(avg))
m3 <- match(as.character(train[, 'date']), names(sds))
train[, 'day_news'] <- counts[m1]
train[, 'day_avg_pop'] <- avg[m2]
train[, 'day_sd_pop'] <- sds[m3]
# New variables
new.vars <- c('date', 'since_20130101', 'year', 'month', 'day', 'is_2013',
'is_2014', 'is_jan', 'is_feb', 'is_mar', 'is_apr', 'is_may',
'is_jun', 'is_jul', 'is_aug', 'is_sep', 'is_oct', 'is_nov',
'is_dec', 'season', 'timedelta_bin', 'timedelta_bin_int',
'kw_min_min_cat0', 'kw_min_min_cat1', 'kw_min_min_cat2',
'kw_avg_max_bin', 'kw_min_avg_bin', 'LDA_01_bin', 'LDA_02_bin',
'LDA_03_bin', 'LDA_04_bin', 'title_subjectivity_cat0',
'title_subjectivity_cat1', 'title_subjectivity_cat2',
'is_outlier', 'title_sentiment_polarity_cat0',
'title_sentiment_polarity_cat1',
'title_sentiment_polarity_cat2', 'day_news', 'day_avg_pop',
'day_sd_pop')
# Standardized features
std.vars <- c('n_tokens_title', 'n_tokens_content', 'kw_avg_min',
'kw_max_max', 'kw_min_avg')
for (col in std.vars) {
end.col <- paste(col, 'std', sep = '_')
train[, end.col] <- (train[, col] - mean(train[, col])) / sd(train[, col])
}
#Â Logarithmic variables
log.vars <- c('timedelta', 'kw_max_min', 'kw_min_max', 'kw_avg_max',
'kw_max_avg', 'kw_avg_avg', 'self_reference_min_shares',
'self_reference_max_shares', 'self_reference_avg_sharess')
for (col in log.vars) {
end.col <- paste('log', col, sep = '_')
train[, end.col] <- log(train[, col] + 1)
}
#Â New features added
std.cols <- paste(std.vars, 'std', sep = '_')
log.cols <- paste('log', log.vars, sep = '_')
#Â Final variables
final.vars <- c(nat.vars, new.vars, std.cols, log.cols)
##############################################################################
##############################################################################
# Test set
##############################################################################
#Â See if some observations can be considered outliers
killed <- c()
for (col in nat.vars) {
if (col != 'popularity' && class(test[, col]) != 'character') {
outliers <- which(test[, col] > max(extremes[, col]) |
test[, col] < min(extremes[, col]))
killed <- unique(c(killed, outliers))
}
}
#killed <- killed[-which(killed %in% fives)]
cat('Total number of observations ("test"):', nrow(test), '\n')
cat('Number of outliers detected ("test"):', length(killed), '\n')
#Â Creating new variables (same as for training set)
# Binary for outliers
test[, 'is_outlier'] <- 0
test[killed, 'is_outlier'] <- 1
# Binary for timedelta
test[, 'timedelta_bin'] <- as.numeric(test[, 'timedelta'] >= 400)
test[, 'timedelta_bin_int'] <- test[, 'timedelta'] * test[, 'timedelta_bin']
# Categorical for kw_min_min
test[, 'kw_min_min_cat0'] <- 0
test[, 'kw_min_min_cat1'] <- 0
test[, 'kw_min_min_cat2'] <- 0
test[which(test[, 'kw_min_min'] ==  -1), 'kw_min_min_cat0'] <- 1
test[which(test[, 'kw_min_min'] ==   4), 'kw_min_min_cat1'] <- 1
test[which(test[, 'kw_min_min'] == 217), 'kw_min_min_cat2'] <- 1
# Binary kw_avg_max
test[, 'kw_avg_max_bin'] <- as.numeric(test[, 'kw_avg_max'] >= 1e5)
#Â Binary kw_min_avg
test[, 'kw_min_avg_bin'] <- as.numeric(test[, 'kw_min_avg'] >= 0)
#Â Binary LDA_0x
test[, 'LDA_01_bin'] <- as.numeric(test[, 'LDA_01'] < 0.1)
test[, 'LDA_02_bin'] <- as.numeric(test[, 'LDA_02'] < 0.1)
test[, 'LDA_03_bin'] <- as.numeric(test[, 'LDA_03'] < 0.1)
test[, 'LDA_04_bin'] <- as.numeric(test[, 'LDA_04'] < 0.1)
test[, 'LDA_01_bin_int'] <- test[, 'LDA_01'] * test[, 'LDA_01_bin']
test[, 'LDA_02_bin_int'] <- test[, 'LDA_02'] * test[, 'LDA_02_bin']
test[, 'LDA_03_bin_int'] <- test[, 'LDA_03'] * test[, 'LDA_03_bin']
test[, 'LDA_04_bin_int'] <- test[, 'LDA_04'] * test[, 'LDA_04_bin']
#Â Categorical title_subjectivity
q0 <- which(test[, 'title_subjectivity'] <  0.15)
q1 <- which(test[, 'title_subjectivity'] >= 0.15)
q2 <- which(test[, 'title_subjectivity'] >= 0.6)
test[, 'title_subjectivity_cat0'] <- 0
test[, 'title_subjectivity_cat1'] <- 0
test[, 'title_subjectivity_cat2'] <- 0
test[q0, 'title_subjectivity_cat0'] <- 1
test[q1, 'title_subjectivity_cat1'] <- 1
test[q2, 'title_subjectivity_cat2'] <- 1
# Categorical title_sentiment_polarity
q0 <- which(test[, 'title_sentiment_polarity'] <  0)
q1 <- which(test[, 'title_sentiment_polarity'] == 0)
q2 <- which(test[, 'title_sentiment_polarity'] >  0)
test[, 'title_sentiment_polarity_cat0'] <- 0
test[, 'title_sentiment_polarity_cat1'] <- 0
test[, 'title_sentiment_polarity_cat2'] <- 0
test[q0, 'title_sentiment_polarity_cat0'] <- 1
test[q1, 'title_sentiment_polarity_cat1'] <- 1
test[q2, 'title_sentiment_polarity_cat2'] <- 1
# Extract the date
urls <- strsplit(test[, 'url'], '/')
days <- sapply(urls, `[`, 6)
years <- sapply(urls, `[`, 4)
month <- sapply(urls, `[`, 5)
dates <- paste(years, month, days, sep = '-')
#Â Date
day.one <- as.Date('2013-01-01', '%Y-%m-%d')
test[, 'date'] <- as.Date(dates, '%Y-%m-%d')
test[, 'since_20130101'] <- as.numeric(test[, 'date'] - day.one)
# Year
test[, 'year'] <- years
test[, 'is_2013'] <- as.numeric(test[, 'year'] == '2013')
test[, 'is_2014'] <- as.numeric(test[, 'year'] == '2014')
# Month
test[, 'month'] <- month
test[, 'is_jan'] <- as.numeric(test[, 'month'] == '01')
test[, 'is_feb'] <- as.numeric(test[, 'month'] == '02')
test[, 'is_mar'] <- as.numeric(test[, 'month'] == '03')
test[, 'is_apr'] <- as.numeric(test[, 'month'] == '04')
test[, 'is_may'] <- as.numeric(test[, 'month'] == '05')
test[, 'is_jun'] <- as.numeric(test[, 'month'] == '06')
test[, 'is_jul'] <- as.numeric(test[, 'month'] == '07')
test[, 'is_aug'] <- as.numeric(test[, 'month'] == '08')
test[, 'is_sep'] <- as.numeric(test[, 'month'] == '09')
test[, 'is_oct'] <- as.numeric(test[, 'month'] == '10')
test[, 'is_nov'] <- as.numeric(test[, 'month'] == '11')
test[, 'is_dec'] <- as.numeric(test[, 'month'] == '12')
# Day
test[, 'day'] <- days
# Season
test[, 'season'] <- '4'  # Winter
test[which(paste(month, days) > '03 20'), 'season'] <- '1'  #Â Spring
test[which(paste(month, days) > '06 20'), 'season'] <- '2'  # Summer
test[which(paste(month, days) > '09 20'), 'season'] <- '3'  # Autumn
test[which(paste(month, days) > '12 20'), 'season'] <- '4'  #Â Winter
test[, 'is_spring'] <- as.numeric(test[, 'season'] == '1')
test[, 'is_summer'] <- as.numeric(test[, 'season'] == '2')
test[, 'is_autumn'] <- as.numeric(test[, 'season'] == '3')
test[, 'is_winter'] <- as.numeric(test[, 'season'] == '4')
# Daily scores
m1 <- match(as.character(test[, 'date']), names(counts))
m2 <- match(as.character(test[, 'date']), names(avg))
m3 <- match(as.character(test[, 'date']), names(sds))
test[, 'day_news'] <- counts[m1]
test[, 'day_avg_pop'] <- avg[m2]
test[, 'day_sd_pop'] <- sds[m3]
# Standardized features
for (col in std.vars) {
end.col <- paste(col, 'std', sep = '_')
test[, end.col] <- (test[, col] - mean(test[, col])) / sd(test[, col])
}
#Â Logarithmic variables
for (col in log.vars) {
end.col <- paste('log', col, sep = '_')
test[, end.col] <- log(test[, col] + 1)
}
return(test)
}
library(randomForest)
#load("../../matthew/train") #train
#load("../../matthew/test") #test
#load("../../matthew/vars") #model.varsT
build_models <- function()
{
seed <- 3050
for (a1 in 0:1) {
for (a2 in 0:1) {
for (a3 in 0:1) {
for (a4 in 0:1) {
for (a5 in 0:1) {
s <- c(a1,a2,a3,a4,a5)
n <- s*(1:5)
u <- n[n>0]
if (sum(s) > 0 && sum(s) != 4)
{
t <- paste(u, collapse="")
print(t)
local.train <- train
local.train$popularity[!(local.train$popularity %in% n)] <- 9
rf <- randomForest(y=as.factor(local.train$popularity), x=local.train[, model.varsT],
ntree=1200, nodesize=10)
preds <- as.data.frame(id=test$id, pred<-predict(rf, newdata=test))
write.csv(preds, file=paste("../../matthew/predsCV",t,".csv",sep=""))
save(rf,file=paste("../../matthew/rfCV.RData",t,sep=""))
}
}
}
}
}
}
train <- rbind(train,test)
seed <- 3050
for (a1 in 0:1) {
for (a2 in 0:1) {
for (a3 in 0:1) {
for (a4 in 0:1) {
for (a5 in 0:1) {
s <- c(a1,a2,a3,a4,a5)
n <- s*(1:5)
u <- n[n>0]
if (sum(s) > 0 && sum(s) != 4)
{
t <- paste(u, collapse="")
print(t)
local.train <- train
local.train$popularity[!(local.train$popularity %in% n)] <- 9
rf <- randomForest(y=as.factor(local.train$popularity), x=local.train[, model.varsT],
ntree=1200, nodesize=10)
preds <- as.data.frame(id=test$id, pred<-predict(rf, newdata=test))
write.csv(preds, file=paste("../../matthew/predsFull",t,".csv",sep=""))
save(rf,file=paste("../../matthew/rfFull.RData",t,sep=""))
}
}
}
}
}
}
}
get_raw_results_from_models <- function(data)
{
results <- data.frame(id=data$id)
for (a1 in 0:1) {
for (a2 in 0:1) {
for (a3 in 0:1) {
for (a4 in 0:1) {
for (a5 in 0:1) {
s <- c(a1,a2,a3,a4,a5)
n <- s*(1:5)
u <- n[n>0]
if (sum(s) > 0 && sum(s) != 4)
{
t <- paste(u, collapse="")
modelName <- paste("T", t, sep="")
cat(paste("Loading model", modelName, '\n'))
load(paste("../../matthew/rfFull.RData",t,sep="")) #this sets rf
cat("Predicting\n")
predictions <- predict(rf, newdata=data)
results[,modelName] <- predictions
}
}
}
}
}
}
# Eliminate the models that made the same prediction for every row.
#   for (col in seq(ncol(results),2,-1))
#   {
#     if (length(unique(results[,col])) == 1)
#     {
#       results <- results[,-col]
#     }
#   }
return(results)
}
arrange_all_possible_steps <- function(raw_results, data)
{
m <- matrix(0, 5, 22)
for (col in 2:23)
{
trial <- colnames(raw_results)[col]
cat(paste("Arranging steps for", trial, '\n'))
preds <- data.frame(data$popularity, raw_results[,col])
colnames(preds) <- c('truth','pred')
preds <- preds[!is.na(preds$pred),]
correct <- sum(preds$truth == preds$pred)
total <- nrow(preds)
score <- ifelse(total==0,0,correct/total)
for (i in 1:5)
{
temp <- preds[preds$pred == i,]
score <- mean(temp$truth == i)
m[i,col-1] <- ifelse(is.nan(score), 0, score)
}
}
return(m)
}
generate_plan <- function(raw_results, m, data)
{
cat("Generating plan\n")
plan.models <- c()
plan.popularity <- c()
plan.score <- c()
plan.num_removed <- c()
raw_names <- colnames(raw_results)
ids <- data$id
maxmax <- 1
while (nrow(raw_results) > 0 && maxmax > 0)
{
maxes <- rep(0,5)
for (i in 1:5)
{
maxes[i] <- max(m[i,])
}
maxmax <- max(maxes)
chosen.i <- which.max(maxes)
chosen.c <- which.max(m[chosen.i,])
raw_results.remove <- (raw_results[,chosen.c+1]==chosen.i)
raw_results.keep <- (raw_results[,chosen.c+1]!=chosen.i)
raw_results <- raw_results[raw_results.keep,]
cat(paste("Generate step", raw_names[chosen.c+1], "(", chosen.i, ")\n"))
plan.models <- c(plan.models, raw_names[chosen.c+1])
plan.popularity <- c(plan.popularity, chosen.i)
plan.score <- c(plan.score, maxmax)
plan.num_removed <- c(plan.num_removed, sum(raw_results.remove))
m[chosen.i, chosen.c] <- 0
}
plan <- data.frame(models=plan.models, popularity=plan.popularity, score=plan.score, num_removed=plan.num_removed)
return(plan)
}
execute_plan <- function(raw_results, data, plan)
{
cat("Executing plan\n")
decisions <- data.frame(id=data$id)
decisions$popularity <- 0
decisions$model <- ""
for (step in 1:nrow(plan))
{
modelName <- as.character(plan$models[step])
popularity <- plan$popularity[step]
modelPredictions <- raw_results[,modelName]
decisions$model[decisions$popularity==0 & modelPredictions==popularity] <- modelName
decisions$popularity[decisions$popularity==0 & modelPredictions==popularity] <- popularity
}
# Pick up any stragglers and predict them as a 2.  This should never actually be needed.
decisions$popularity[decisions$popularity==0] <- 2
return(decisions)
}
build_master_plan <- function()
{
load("../../matthew/test") #test (contains popularity column needed for generating plan)
raw_results <- get_raw_results_from_models(test)
steps <- arrange_all_possible_steps(raw_results, test)
plan <- generate_plan(raw_results, steps, test)
save(plan, file="../../matthew/plan")
}
run_master_plan <- function()
{
load("../../matthew/plan")
load("../../data/news_popularity_training.RData") #np.train
load("../../data/news_popularity_test.RData") #np.test
np.test <- massageTestSet(np.train, np.test)
raw_results <- get_raw_results_from_models(np.test)
preds <- execute_plan(raw_results, np.test, plan)
preds$model <- NULL
write.csv(preds, file='submission.csv', row.names=FALSE)
#print(paste("Baseline =", mean(raw_results$T12345==data$popularity)))
}
build_master_plan()
run_master_plan()
run_master_plan <- function()
{
load("../../matthew/plan")
load("../../data/news_popularity_training.RData") #np.train
#load("../../data/news_popularity_test.RData") #np.test
#np.test <- massageTestSet(np.train, np.test)
load("../../matthew/test")
np.test <- test
raw_results <- get_raw_results_from_models(np.test)
preds <- execute_plan(raw_results, np.test, plan)
preds$model <- NULL
write.csv(preds, file='../../matthew/submission.csv', row.names=FALSE)
#print(paste("Baseline =", mean(raw_results$T12345==data$popularity)))
}
run_master_plan()
run_master_plan <- function()
{
load("../../matthew/plan")
load("../../data/news_popularity_training.RData") #np.train
#load("../../data/news_popularity_test.RData") #np.test
#np.test <- massageTestSet(np.train, np.test)
load("../../matthew/test")
np.test <- test
raw_results <- get_raw_results_from_models(np.test)
preds <- execute_plan(raw_results, np.test, plan)
preds$model <- NULL
print(np.test$popularity==preds$popularity)
#write.csv(preds, file='../../matthew/submission.csv', row.names=FALSE)
#print(paste("Baseline =", mean(raw_results$T12345==data$popularity)))
}
run_master_plan()
run_master_plan <- function()
{
load("../../matthew/plan")
load("../../data/news_popularity_training.RData") #np.train
#load("../../data/news_popularity_test.RData") #np.test
#np.test <- massageTestSet(np.train, np.test)
load("../../matthew/test")
np.test <- test
raw_results <- get_raw_results_from_models(np.test)
preds <- execute_plan(raw_results, np.test, plan)
preds$model <- NULL
print(sum(np.test$popularity==preds$popularity))
#write.csv(preds, file='../../matthew/submission.csv', row.names=FALSE)
#print(paste("Baseline =", mean(raw_results$T12345==data$popularity)))
}
run_master_plan()
load("../../matthew/test")
nrow(np.test)
nrow(test)
6092/6289
